{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the Scientific Python (scipy) stack tools to generate flow duration curves from current USGS NWIS data.\n",
    "\n",
    "Using recipes from this notebook, you can make:\n",
    "* USGS Station Summaries\n",
    "* Flow duration curves\n",
    "* Iterative import and compilation of USGS station information and data\n",
    "* boxplots using pandas\n",
    "* iterative charts (one monthly summary boxplot per station)\n",
    "* Gantt charts of USGS stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out this for some great `pandas` applications:\n",
    "http://earthpy.org/time_series_analysis_with_pandas_part_2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import platform\n",
    "import sys\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "from datetime import datetime, date, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import wellapplication as wa\n",
    "import matplotlib\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating System Linux 3.19.0-43-generic\n",
      "Python Version 2.7.6 (default, Jun 22 2015, 17:58:13) \n",
      "[GCC 4.8.2]\n",
      "Pandas Version 0.17.1\n",
      "Numpy Version 1.10.4\n",
      "Matplotlib Version 1.5.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Operating System \" + platform.system() + \" \" + platform.release())\n",
    "print(\"Python Version \" + str(sys.version))\n",
    "print(\"Pandas Version \" + str(pd.__version__))\n",
    "print(\"Numpy Version \" + str(np.__version__))\n",
    "print(\"Matplotlib Version \" + str(matplotlib.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wa.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call function class usgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USGS = wa.usgs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import list of stations based on Cache Valley HUCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stations = USGS.getStationsfromHUC(str('16010203,16010202'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import site data from HUCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "siteinfo = USGS.getStationInfoFromHUC(str('16010203,16010202'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect columns of imported site data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "siteinfo.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproject Lat Long into UTM X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "siteinfo['UTM_X'] = siteinfo[['dec_long_va','dec_lat_va']].apply(lambda x: wa.avgMeths.projx(x),1)\n",
    "siteinfo['UTM_Y']= siteinfo[['dec_long_va','dec_lat_va']].apply(lambda x: wa.avgMeths.projy(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "siteinfo['Elev'] = siteinfo[['dec_long_va','dec_lat_va']].apply(lambda x: USGS.getelev(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "siteinfo['USGSid'] = siteinfo[['dec_long_va','dec_lat_va']].apply(lambda x: USGS.USGSID(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = USGS.getWLfromHUC(str('16010203,16010202'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.drop([u'agency_cd', u'site_tp_cd'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stationWL = pd.merge(data, siteinfo, on='site_no', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stationWL = stationWL[~stationWL['lev_status_cd'].isin(['Z', 'R', 'V', 'P', 'O', 'F', 'W', 'G', 'S', 'C', 'E', 'N'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stationWL['wlelev'] = stationWL[['lev_va','Elev']].apply(lambda x: wa.avgMeths.getwlelev(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stationWL['date'], stationWL['Year'], stationWL['Month'] = zip(*stationWL['lev_dt'].apply(lambda x: wa.avgMeths.getyrmnth(x),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try using diff function to get average monthly changes over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hucPlot(16030006) #cedar city valley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hucPlot(16020204) #salt lake valley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stationWL.reset_index(inplace=True)\n",
    "stationWL.set_index('date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wlavgs = stationWL[['Year','Month','site_no','lev_va','UTM_X','UTM_Y']].groupby(['Year','Month','site_no']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grpstat = stationWL.groupby('site_no')['lev_va'].agg([np.std,np.mean,np.median, np.min,np.max,np.size]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USGS_Site_Inf = stationWL.groupby('site_no')['lev_dt'].agg([np.min,np.max,np.size]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "siteinfo.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grpst = pd.merge(grpstat, USGS_Site_Inf, on='site_no', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grpsta = pd.merge(grpst, siteinfo, on='site_no', how='left')\n",
    "avgwls = grpsta.drop_duplicates()\n",
    "#avgwls.to_csv('E:\\\\PROJECTS\\\\UMAR\\\\Data\\\\USGS\\\\AvgWLs_USGS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "USGS_Site_Info = USGS_Site_Inf[USGS_Site_Inf['size']>50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wlLong = stationWL[stationWL['site_no'].isin(list(USGS_Site_Info['site_no'].values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wlLongStats = pd.merge(wlLong,grpstat, on='site_no', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wlLongStats['levDiff'] = wlLongStats['lev_va'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wlLongStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wlLongStats['stdWL'] = wlLongStats[['lev_va','mean','std']].apply(lambda x: wa.avgMeths.stndrd(x),1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wlLongStats['YRMO'] = wlLongStats[['Year','Month']].apply(lambda x: wa.avgMeths.yrmo(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wlLongStats['date'] = wlLongStats[['Year','Month']].apply(lambda x: wa.avgMeths.adddate(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "wlLongStats.groupby(['Month'])['stdWL'].mean().to_frame().plot()\n",
    "#wlLongStats.groupby(['Month'])['stdWL'].std().to_frame().plot()\n",
    "\n",
    "#wlLongStats.groupby(['Month'])['stdWL'].(np.mean+np.std).plot()\n",
    "plt.xticks([1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.dates \n",
    "from matplotlib.dates import YearLocator\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "\n",
    "wlLongStatsGroups = wlLongStats.groupby(['date'])['stdWL'].agg({'mean':np.mean,'median':np.median,'standard':np.std, \n",
    "                                                                'cnt':(lambda x: np.count_nonzero(~np.isnan(x))), 'err':(lambda x: 1.96*np.std(x)/np.count_nonzero(~np.isnan(x)))})\n",
    "wlLongStatsGroups2 = wlLongStats.groupby(['date'])['levDiff'].agg([np.mean,np.median,np.std])\n",
    "\n",
    "wlLongStatsGroups['meanpluserr'] = wlLongStatsGroups['mean'] + wlLongStatsGroups['err']\n",
    "wlLongStatsGroups['meanminuserr'] = wlLongStatsGroups['mean'] - wlLongStatsGroups['err']\n",
    "\n",
    "wlLongSt = wlLongStatsGroups[wlLongStatsGroups['cnt']>2]\n",
    "\n",
    "#x1 = pd.\n",
    "x = wlLongSt.index\n",
    "y = wlLongSt['mean']\n",
    "ax.plot(x,y,label='Average Groundwater Level Variation')\n",
    "\n",
    "ax.fill_between(wlLongSt.index, wlLongSt['meanpluserr'], wlLongSt['meanminuserr'], \n",
    "                 facecolor='blue', alpha=0.4, linewidth=0.5, label= \"Std Error\")\n",
    "locator = YearLocator(2)\n",
    "minlocator = YearLocator(1)\n",
    "# Plotting stuff here ...\n",
    "# Set major x ticks on Mondays.\n",
    "plt.xlim('1/1/1945','1/1/2015')\n",
    "ax.xaxis.set_major_locator(locator)\n",
    "ax.xaxis.set_minor_locator(minlocator)\n",
    "plt.grid(which='both')\n",
    "plt.ylabel('z-score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.title('Average Groundwater Level Variation in Cache Valley, Utah and Idaho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wlLongStatsGroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wlLongStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "x = wlLongStatsGroups.index\n",
    "y = wlLongStatsGroups['mean']\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# designate variables\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 10\n",
    "from matplotlib.pyplot import cm \n",
    "x2 = USGS_Site_Info['amax'].astype(np.datetime64).values\n",
    "x1 = USGS_Site_Info['amin'].astype(np.datetime64).values\n",
    "z = USGS_Site_Info['size'].values.astype(np.int)\n",
    "y = USGS_Site_Info.index.astype(np.int)\n",
    "names = USGS_Site_Info.site_no.values\n",
    "\n",
    "labs, tickloc, col = [], [], []\n",
    "\n",
    "# create color iterator for multi-color lines in gantt chart\n",
    "color=iter(cm.Dark2(np.linspace(0,1,len(y))))\n",
    "\n",
    "plt.figure(figsize=[20,20])\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# generate a line and line properties for each station\n",
    "for i in range(len(y)):\n",
    "    c=next(color)\n",
    "    \n",
    "    plt.hlines(i+1, x1[i], x2[i], label=y[i], color=c, linewidth=2)\n",
    "    labs.append(str(names[i]).title()+\" ( n= \"+str(z[i])+\")\")\n",
    "    tickloc.append(i+1)\n",
    "    col.append(c)\n",
    "plt.ylim(0,len(y)+1)\n",
    "plt.yticks(tickloc, labs)\n",
    "\n",
    "# create custom x labels\n",
    "#plt.xticks(np.arange(datetime(np.min(x1).year,1,1),np.max(x2)+timedelta(days=365.25),timedelta(days=365.25*5)),rotation=45)\n",
    "#plt.xlim(datetime(np.min(x1).year,1,1),np.max(x2)+timedelta(days=365.25))\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('USGS Official Station Id')\n",
    "plt.grid()\n",
    "plt.title('USGS Station Measurement Duration')\n",
    "# color y labels to match lines\n",
    "gytl = plt.gca().get_yticklabels()\n",
    "for i in range(len(gytl)):\n",
    "    gytl[i].set_color(col[i])\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('E:\\\\PROJECTS\\\\UMAR\\\\Data\\\\USGS\\\\gantt.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stationWL['Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wlLongStats.to_csv('E:\\\\PROJECTS\\\\UMAR\\\\Data\\\\USGS\\\\AvgWLs_HUC_16010203.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = stationWL.wlelev.values\n",
    "x = stationWL.UTM_X.values\n",
    "y = stationWL.UTM_Y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://connor-johnson.com/2014/03/20/simple-kriging-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://stackoverflow.com/questions/31124930/ckdtree-vs-dsearchn?lq=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following script will generate a series of box and whisker plots and save them in a pdf. It makes a box plot for each station, breaking the data into monthly intervals.  Make sure to change the directory name in the script so it ends up in a recognizable place on your computer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create dictionary of integers and their month equivalent\n",
    "months = {'1':'Jan.', '2':'Feb.', '3':'Mar.', '4':'Apr.', '5':'May', '6':'Jun.', \n",
    "         '7':'Jul.', '8':'Aug.', '9':'Sep.', '10':'Oct.', '11':'Nov.', '12':'Dec.', 'Total':'Total'}\n",
    "# create empty dictionary to hold pandas Dataframes\n",
    "j = {}\n",
    "\n",
    "\n",
    "with PdfPages(rootname + 'station_boxplots.pdf') as pdfs:\n",
    "    ymax = 10000\n",
    "    ymin = 0.01\n",
    "    for i in range(len(sites)):\n",
    "        # make a dataframe containing summary statistics and store it in the j dictionary\n",
    "        j[sites[i]] = USGS_Site_Data.groupby('mon')[sites[i]].agg({'min':np.min, 'mean':np.mean, \n",
    "                                                                   'median':np.median, 'max':np.max, 'std':np.std, \n",
    "                                                                   'cnt':(lambda x: np.count_nonzero(~np.isnan(x)))}).reset_index()\n",
    "        # make a list of the custom lables you will use for your boxplot; this one will show the number of samples used to make the plot\n",
    "        labs = [months[(str(j[sites[i]]['mon'][b]))] + \" (n=\" + str(int(j[sites[i]]['cnt'][b])) + \")\" for b in range(len(j[sites[i]]))]\n",
    "        # designate the location of each custom label\n",
    "        tickloc = [b+1 for b in range(len(j[sites[i]]['mon']))]\n",
    "        \n",
    "        plt.figure()\n",
    "        USGS_Site_Data.boxplot(column=sites[i],by='mon', rot=70)\n",
    "        strtdt = str(USGS_Site_Info.ix[sites[i],'start_date'])[0:10]\n",
    "        findt = str(USGS_Site_Info.ix[sites[i],'fin_date'])[0:10]\n",
    "        siteName = USGS_Site_Info.ix[sites[i],'name'].title() \n",
    "        plt.title( siteName + ' (' + sites[i] + ')  ' + strtdt + ' to ' + findt )\n",
    "        plt.suptitle('')\n",
    "        plt.yscale('log')\n",
    "        plt.ylabel('Discharge (cfs)')\n",
    "        plt.ylim((ymin,ymax))\n",
    "        plt.xlabel('Month')\n",
    "        # here is where your lists for the custom label come into play\n",
    "        plt.xticks(tickloc, labs)\n",
    "        \n",
    "        pdfs.savefig()\n",
    "\n",
    "        plt.close()\n",
    "    # Save metadata of the pdf so you can find it later\n",
    "    d = pdfs.infodict()\n",
    "    d['Title'] = 'Monthly Station USGS Boxplots UMSS'\n",
    "    d['Author'] = u'Paul C. Inkenbrandt\\xe4nen'\n",
    "    d['Subject'] = 'Boxplots of several USGS Surface Stations'\n",
    "    d['Keywords'] = 'USGS Surface NWIS Boxplot'\n",
    "    d['CreationDate'] = datetime.today()\n",
    "    d['ModDate'] = datetime.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot a few of the boxplots so you can see what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1,3):\n",
    "    j[sites[i]] = USGS_Site_Data.groupby('mon')[sites[i]].agg([np.min, np.mean, np.median, np.max, np.std, np.size]).reset_index()\n",
    "    # make a list of the custom lables you will use for your boxplot; this one will show the number of samples used to make the plot\n",
    "    labs = [months[(str(j[sites[i]]['mon'][b]))] + \" (n=\" + str(int(j[sites[i]]['size'][b])) + \")\" for b in range(len(j[sites[i]]))]\n",
    "    # designate the location of each custom label\n",
    "    tickloc = [b+1 for b in range(len(j[sites[i]]['mon']))]\n",
    "\n",
    "    plt.figure()\n",
    "    USGS_Site_Data.boxplot(column=sites[i],by='mon', rot=70)\n",
    "    plt.title(USGS_Site_Info.ix[sites[i],'name'].title() + ' (' + sites[i] + ')')\n",
    "    plt.suptitle('')\n",
    "    plt.yscale('log')\n",
    "    plt.ylabel('Discharge (cfs)')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.xlabel('Month')\n",
    "    # here is where your lists for the custom label come into play\n",
    "    plt.xticks(tickloc, labs)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script will generate boxplots showing all of the station data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This script summarizes discharge for all sites and limits the number of box plots on one graph to the n variable\n",
    "j=0\n",
    "with PdfPages(rootname + 'sum_boxplots.pdf') as pdf:\n",
    "    while j < len(sites):\n",
    "        ymax = 10000\n",
    "        ymin = 0.01\n",
    "        n=10\n",
    "        # if statement allows for uneven number of sites on last page\n",
    "        if j+n >= len(sites):\n",
    "            plt.figure()\n",
    "            USGS_Site_Data[sites[j:-1]].plot(kind='box')\n",
    "            plt.title('Sites '+sites[j]+' to '+sites[-1] )\n",
    "            plt.yscale('log')\n",
    "            plt.xlabel('USGS Site')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.ylabel('discharge (cfs)')\n",
    "            plt.ylim((ymin,ymax))\n",
    "            pdf.savefig()\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            j = j+n\n",
    "        else:\n",
    "            plt.figure()\n",
    "            USGS_Site_Data[sites[j:j+n]].plot(kind='box')\n",
    "            plt.title('Sites '+sites[j]+' to '+sites[j+n] )\n",
    "            plt.yscale('log')\n",
    "            plt.xlabel('USGS Site')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.ylabel('discharge (cfs)')\n",
    "            plt.ylim((ymin,ymax))\n",
    "            pdf.savefig()\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            j = j+n\n",
    "        # Save metadata of the pdf so you can find it later\n",
    "        d = pdf.infodict()\n",
    "        d['Title'] = 'Summary USGS Boxplots UMSS'\n",
    "        d['Author'] = u'Paul C. Inkenbrandt\\xe4nen'\n",
    "        d['Subject'] = 'Boxplots of several USGS Surface Stations'\n",
    "        d['Keywords'] = 'USGS Surface NWIS Boxplot'\n",
    "        d['CreationDate'] = datetime.today()\n",
    "        d['ModDate'] = datetime.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also produce hydrographs of each station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xmax = USGS_Site_Data.index.astype(datetime).values[-1]\n",
    "xmin = USGS_Site_Data.index.astype(datetime).values[0]\n",
    "\n",
    "pdfs = PdfPages(rootname + 'station_hydrographs.pdf')\n",
    "ymax = 10000\n",
    "ymin = 0.1\n",
    "for i in range(len(sites)):\n",
    "    x = USGS_Site_Data.index.values\n",
    "    y = USGS_Site_Data[sites[i]].values\n",
    "    plt.figure()\n",
    "    plt.plot(x,y)\n",
    "    strtdt = str(USGS_Site_Info.ix[sites[i],'start_date'])[0:10]\n",
    "    findt = str(USGS_Site_Info.ix[sites[i],'fin_date'])[0:10]\n",
    "    siteName = USGS_Site_Info.ix[sites[i],'name'].title() \n",
    "    plt.title( siteName + ' (' + sites[i] + ')  ' + strtdt + ' to ' + findt )\n",
    "    plt.suptitle('')\n",
    "    plt.yscale('log')\n",
    "    plt.ylabel('Discharge (cfs)')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.xlabel('Year')\n",
    "    plt.xticks(np.arange(datetime(1905,1,1),xmax+timedelta(days=365.25),timedelta(days=365.25*5)),rotation=45)\n",
    "    plt.xlim(xmin,xmax)\n",
    "    pdfs.savefig()\n",
    "    plt.close()\n",
    "    # Save metadata of the pdf so you can find it later\n",
    "\n",
    "d = pdfs.infodict()\n",
    "d['Title'] = 'Monthly Station USGS Hydrographs UMSS'\n",
    "d['Author'] = u'Paul C. Inkenbrandt\\xe4nen'\n",
    "d['Subject'] = 'Hydrograph of several USGS Surface Stations'\n",
    "d['Keywords'] = 'USGS Surface NWIS Hydrograph'\n",
    "d['CreationDate'] = datetime.today()\n",
    "d['ModDate'] = datetime.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.date_range(start=xmin, end=xmax, freq='5AS').year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xmax = USGS_Site_Data.index[-1]\n",
    "xmin = USGS_Site_Data.index[0]\n",
    "\n",
    "plt.figure()\n",
    "ticks = pd.date_range(start=xmin, end=xmax, freq='4AS')\n",
    "USGS_Site_Data[sites[0:3]].plot(subplots=True,sharex=True,figsize=(10,8),logy=True, rot=90)\n",
    "plt.xlim(xmin,xmax)\n",
    "labs = pd.date_range(start=xmin, end=xmax, freq='4AS').year\n",
    "plt.xticks(ticks,labs)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lumped_hydro(i1,i2):\n",
    "    pdfs = PdfPages(rootname + 'station_hydrographs_lumped.pdf')\n",
    "    plt.figure()\n",
    "    ticks = pd.date_range(start=xmin, end=xmax, freq='4AS')\n",
    "    USGS_Site_Data[sites[i1:i2]].plot(subplots=True, sharex=True, figsize=(10,24),logy=True, rot=90)\n",
    "    plt.xlim(xmin,xmax)\n",
    "    labs = pd.date_range(start=xmin, end=xmax, freq='4AS').year\n",
    "    plt.xticks(ticks,labs)\n",
    "    pdfs.savefig()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lumped_hydro(0,10)\n",
    "lumped_hydro(10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lumped_hydro(20,30)\n",
    "lumped_hydro(30,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dic2df(dic,head):\n",
    "    df = pd.DataFrame(data=dic)\n",
    "    df = df.transpose()\n",
    "    df.columns = [str(head)+'_var1',str(head)+'_var2',str(head)+'_var3',str(head)+'_var4',str(head)+'_r2',str(head)+'_err']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://stackoverflow.com/questions/15408371/cumulative-distribution-plots-python <br>\n",
    "http://hydroclimpy.sourceforge.net/installation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following script if you want to see a map of your stations.  This assumes that you have the <a href=http://sourceforge.net/projects/matplotlib/files/matplotlib-toolkits/>Basemap package</a> installed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
